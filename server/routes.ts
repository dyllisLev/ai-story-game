import type { Express } from "express";
import { createServer, type Server } from "http";
import { storage } from "./storage";
import { insertStorySchema, insertSessionSchema, insertMessageSchema } from "@shared/schema";
import { z } from "zod";
import multer from "multer";
import path from "path";
import fs from "fs";

const uploadDir = path.join(process.cwd(), "uploads");
if (!fs.existsSync(uploadDir)) {
  fs.mkdirSync(uploadDir, { recursive: true });
}

const fileStorage = multer.diskStorage({
  destination: (req, file, cb) => {
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + "-" + Math.round(Math.random() * 1e9);
    cb(null, uniqueSuffix + path.extname(file.originalname));
  },
});

const upload = multer({
  storage: fileStorage,
  limits: { fileSize: 5 * 1024 * 1024 },
  fileFilter: (req, file, cb) => {
    const allowedTypes = /jpeg|jpg|png|gif|webp/;
    const extname = allowedTypes.test(path.extname(file.originalname).toLowerCase());
    const mimetype = allowedTypes.test(file.mimetype);
    if (extname && mimetype) {
      cb(null, true);
    } else {
      cb(new Error("Only image files are allowed"));
    }
  },
});

export async function registerRoutes(
  httpServer: Server,
  app: Express
): Promise<Server> {
  
  // ==================== IMAGE UPLOAD API ====================

  app.use("/uploads", (await import("express")).default.static(uploadDir));

  app.post("/api/upload", upload.single("image"), (req, res) => {
    try {
      if (!req.file) {
        return res.status(400).json({ error: "No file uploaded" });
      }
      const imageUrl = `/uploads/${req.file.filename}`;
      res.json({ url: imageUrl });
    } catch (error) {
      res.status(500).json({ error: "Failed to upload image" });
    }
  });

  // ==================== SETTINGS API ====================
  
  app.get("/api/settings", async (req, res) => {
    try {
      const allSettings = await storage.getAllSettings();
      res.json(allSettings);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch settings" });
    }
  });

  app.get("/api/settings/:key", async (req, res) => {
    try {
      const setting = await storage.getSetting(req.params.key);
      if (!setting) {
        return res.status(404).json({ error: "Setting not found" });
      }
      res.json(setting);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch setting" });
    }
  });

  app.post("/api/settings", async (req, res) => {
    try {
      const { key, value } = req.body;
      
      if (!key || value === undefined) {
        return res.status(400).json({ error: "Key and value required" });
      }

      const setting = await storage.setSetting(key, value);
      res.json(setting);
    } catch (error) {
      res.status(500).json({ error: "Failed to save setting" });
    }
  });

  app.post("/api/settings/batch", async (req, res) => {
    try {
      const { settings: settingsData } = req.body;
      
      if (!Array.isArray(settingsData)) {
        return res.status(400).json({ error: "Settings array required" });
      }

      const results = [];
      for (const { key, value } of settingsData) {
        if (key && value !== undefined) {
          const setting = await storage.setSetting(key, value);
          results.push(setting);
        }
      }
      res.json(results);
    } catch (error) {
      res.status(500).json({ error: "Failed to save settings" });
    }
  });

  // ==================== STORIES API ====================

  app.get("/api/stories", async (req, res) => {
    try {
      const allStories = await storage.getAllStories();
      res.json(allStories);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch stories" });
    }
  });

  app.get("/api/stories/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ error: "Invalid story ID" });
      }
      
      const story = await storage.getStory(id);
      if (!story) {
        return res.status(404).json({ error: "Story not found" });
      }
      res.json(story);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch story" });
    }
  });

  app.post("/api/stories", async (req, res) => {
    try {
      const parsed = insertStorySchema.safeParse(req.body);
      if (!parsed.success) {
        return res.status(400).json({ error: "Invalid story data", details: parsed.error });
      }

      const story = await storage.createStory(parsed.data);
      res.status(201).json(story);
    } catch (error) {
      res.status(500).json({ error: "Failed to create story" });
    }
  });

  app.put("/api/stories/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ error: "Invalid story ID" });
      }

      const story = await storage.updateStory(id, req.body);
      if (!story) {
        return res.status(404).json({ error: "Story not found" });
      }
      res.json(story);
    } catch (error) {
      res.status(500).json({ error: "Failed to update story" });
    }
  });

  app.delete("/api/stories/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ error: "Invalid story ID" });
      }

      const deleted = await storage.deleteStory(id);
      if (!deleted) {
        return res.status(404).json({ error: "Story not found" });
      }
      res.json({ success: true });
    } catch (error) {
      res.status(500).json({ error: "Failed to delete story" });
    }
  });

  // ==================== SESSIONS API ====================

  app.get("/api/stories/:storyId/sessions", async (req, res) => {
    try {
      const storyId = parseInt(req.params.storyId);
      if (isNaN(storyId)) {
        return res.status(400).json({ error: "Invalid story ID" });
      }

      const sessions = await storage.getSessionsByStory(storyId);
      res.json(sessions);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch sessions" });
    }
  });

  app.post("/api/stories/:storyId/sessions", async (req, res) => {
    try {
      const storyId = parseInt(req.params.storyId);
      if (isNaN(storyId)) {
        return res.status(400).json({ error: "Invalid story ID" });
      }

      const story = await storage.getStory(storyId);
      if (!story) {
        return res.status(404).json({ error: "Story not found" });
      }

      // Get default provider and model from settings
      const providerSetting = await storage.getSetting("aiProvider");
      const defaultProvider = providerSetting?.value || "gemini";
      
      const defaultModels: Record<string, string> = {
        gemini: "gemini-2.0-flash",
        chatgpt: "gpt-4o",
        claude: "claude-3-5-sonnet-20241022",
        grok: "grok-beta"
      };
      
      const modelSetting = await storage.getSetting(`aiModel_${defaultProvider}`);
      const defaultModel = modelSetting?.value || defaultModels[defaultProvider] || "";

      const parsed = insertSessionSchema.safeParse({
        ...req.body,
        storyId,
        sessionProvider: req.body.sessionProvider || defaultProvider,
        sessionModel: req.body.sessionModel || defaultModel
      });
      if (!parsed.success) {
        return res.status(400).json({ error: "Invalid session data", details: parsed.error });
      }

      const session = await storage.createSession(parsed.data);
      
      // Automatically add prologue as first message if it exists
      if (story.prologue) {
        await storage.createMessage({
          sessionId: session.id,
          role: "assistant",
          content: story.prologue,
          character: "Narrator"
        });
      }
      
      res.status(201).json(session);
    } catch (error: any) {
      console.error("Error creating session:", error);
      res.status(500).json({ error: "Failed to create session", details: error.message });
    }
  });

  app.get("/api/sessions/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ error: "Invalid session ID" });
      }

      const session = await storage.getSession(id);
      if (!session) {
        return res.status(404).json({ error: "Session not found" });
      }
      res.json(session);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch session" });
    }
  });

  app.put("/api/sessions/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ error: "Invalid session ID" });
      }

      const session = await storage.updateSession(id, req.body);
      if (!session) {
        return res.status(404).json({ error: "Session not found" });
      }
      res.json(session);
    } catch (error) {
      res.status(500).json({ error: "Failed to update session" });
    }
  });

  app.delete("/api/sessions/:id", async (req, res) => {
    try {
      const id = parseInt(req.params.id);
      if (isNaN(id)) {
        return res.status(400).json({ error: "Invalid session ID" });
      }

      const deleted = await storage.deleteSession(id);
      if (!deleted) {
        return res.status(404).json({ error: "Session not found" });
      }
      res.json({ success: true });
    } catch (error) {
      res.status(500).json({ error: "Failed to delete session" });
    }
  });

  // ==================== AI MODELS API ====================

  app.post("/api/ai/models", async (req, res) => {
    try {
      const { provider, apiKey } = req.body;
      
      if (!apiKey) {
        return res.status(400).json({ error: "API key is required" });
      }

      let models: { id: string; name: string }[] = [];

      if (provider === "gemini") {
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`
        );
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        models = (data.models || [])
          .filter((m: any) => m.supportedGenerationMethods?.includes("generateContent"))
          .map((m: any) => ({
            id: m.name.replace("models/", ""),
            name: m.displayName || m.name.replace("models/", "")
          }));
      } else if (provider === "chatgpt") {
        const response = await fetch("https://api.openai.com/v1/models", {
          headers: { "Authorization": `Bearer ${apiKey}` }
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        const gptModels = (data.data || [])
          .filter((m: any) => m.id.includes("gpt"))
          .map((m: any) => ({ id: m.id, name: m.id }))
          .sort((a: any, b: any) => b.id.localeCompare(a.id));
        models = gptModels.slice(0, 10);
      } else if (provider === "claude") {
        // Anthropic doesn't have a models list API, return hardcoded list
        models = [
          { id: "claude-3-5-sonnet-20241022", name: "Claude 3.5 Sonnet" },
          { id: "claude-3-opus-20240229", name: "Claude 3 Opus" },
          { id: "claude-3-sonnet-20240229", name: "Claude 3 Sonnet" },
          { id: "claude-3-haiku-20240307", name: "Claude 3 Haiku" },
        ];
        // Verify API key works
        const testResponse = await fetch("https://api.anthropic.com/v1/messages", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01"
          },
          body: JSON.stringify({
            model: "claude-3-haiku-20240307",
            max_tokens: 1,
            messages: [{ role: "user", content: "hi" }]
          })
        });
        if (!testResponse.ok) {
          const errData = await testResponse.json();
          return res.status(400).json({ error: errData.error?.message || "Invalid API key" });
        }
      } else if (provider === "grok") {
        // xAI doesn't have a models list API, return hardcoded list
        models = [
          { id: "grok-beta", name: "Grok Beta" },
          { id: "grok-2-1212", name: "Grok 2" },
        ];
        // Verify API key works
        const testResponse = await fetch("https://api.x.ai/v1/models", {
          headers: { "Authorization": `Bearer ${apiKey}` }
        });
        if (testResponse.ok) {
          const data = await testResponse.json();
          if (data.data) {
            models = data.data.map((m: any) => ({ id: m.id, name: m.id }));
          }
        }
      } else {
        return res.status(400).json({ error: "Unsupported provider" });
      }

      res.json({ models });
    } catch (error: any) {
      console.error("Failed to fetch models:", error);
      res.status(500).json({ error: error.message || "Failed to fetch models" });
    }
  });

  // ==================== AI GENERATE API ====================

  app.post("/api/ai/generate-story-settings", async (req, res) => {
    try {
      const { title, description, genre, promptTemplate, storySettings, provider: requestedProvider } = req.body;
      
      // Try to find an available provider with API key
      const providers = ["gemini", "chatgpt", "claude", "grok"];
      let selectedProvider = requestedProvider;
      let apiKey = "";
      
      if (requestedProvider && requestedProvider !== "auto") {
        // Use requested provider
        const apiKeySetting = await storage.getSetting(`apiKey_${requestedProvider}`);
        if (!apiKeySetting || !apiKeySetting.value) {
          return res.status(400).json({ error: `API key for ${requestedProvider} not configured. Please set it in settings.` });
        }
        apiKey = apiKeySetting.value;
        selectedProvider = requestedProvider;
      } else {
        // Auto-select: find first provider with API key
        for (const p of providers) {
          const apiKeySetting = await storage.getSetting(`apiKey_${p}`);
          if (apiKeySetting && apiKeySetting.value) {
            apiKey = apiKeySetting.value;
            selectedProvider = p;
            break;
          }
        }
        
        if (!apiKey) {
          return res.status(400).json({ error: "No AI API key configured. Please set at least one API key in settings." });
        }
      }
      
      // Get custom prompt template
      const customPromptSetting = await storage.getSetting("storyGeneratePrompt");
      
      // Build prompt with placeholders
      let prompt = customPromptSetting?.value || `ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ìŠ¤í† ë¦¬ ì„¤ì •ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì œëª©: {title}
í•œ ì¤„ ì†Œê°œ: {description}
ì¥ë¥´: {genre}
í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿: {promptTemplate}

ê¸°ì¡´ ì„¤ì •:
{storySettings}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„¸ê³„ê´€, ì£¼ìš” ë“±ì¥ì¸ë¬¼(ì™¸ëª¨, ì„±ê²©, ë§íˆ¬ í¬í•¨), ë°°ê²½ ì„¤ì • ë“±ì„ í¬í•¨í•œ ìƒì„¸í•œ ìŠ¤í† ë¦¬ ì„¤ì •ì„ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì°½ì˜ì ì´ê³  ëª°ì…ê° ìˆëŠ” ì„¤ì •ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.`;

      // Replace placeholders
      prompt = prompt
        .replace(/\{title\}/g, title || "")
        .replace(/\{description\}/g, description || "")
        .replace(/\{genre\}/g, genre || "")
        .replace(/\{promptTemplate\}/g, promptTemplate || "")
        .replace(/\{storySettings\}/g, storySettings || "");

      let generatedText = "";

      // Get selected model for this provider
      const modelSetting = await storage.getSetting(`aiModel_${selectedProvider}`);
      const defaultModels: Record<string, string> = {
        gemini: "gemini-2.0-flash",
        chatgpt: "gpt-4o",
        claude: "claude-3-5-sonnet-20241022",
        grok: "grok-beta"
      };
      const selectedModel = modelSetting?.value || defaultModels[selectedProvider] || "";

      if (selectedProvider === "gemini") {
        // Gemini 3 Pro requires thinking mode, other models can disable it
        const isThinkingOnlyModel = selectedModel.includes("gemini-3-pro") || selectedModel.includes("gemini-2.5-pro");
        const generationConfig: Record<string, any> = { 
          temperature: 0.8, 
          maxOutputTokens: 8192
        };
        if (!isThinkingOnlyModel) {
          generationConfig.thinkingConfig = { thinkingBudget: 0 };
        }

        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/${selectedModel}:generateContent?key=${apiKey}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              contents: [{ parts: [{ text: prompt }] }],
              generationConfig
            })
          }
        );
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.candidates?.[0]?.content?.parts?.[0]?.text || "";
      } else if (selectedProvider === "chatgpt") {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [{ role: "user", content: prompt }],
            temperature: 0.8,
            max_tokens: 8192
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.choices?.[0]?.message?.content || "";
      } else if (selectedProvider === "claude") {
        const response = await fetch("https://api.anthropic.com/v1/messages", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01"
          },
          body: JSON.stringify({
            model: selectedModel,
            max_tokens: 8192,
            messages: [{ role: "user", content: prompt }]
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.content?.[0]?.text || "";
      } else if (selectedProvider === "grok") {
        const response = await fetch("https://api.x.ai/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [{ role: "user", content: prompt }],
            temperature: 0.8,
            max_tokens: 8192
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.choices?.[0]?.message?.content || "";
      } else {
        return res.status(400).json({ error: "Unsupported AI provider" });
      }

      res.json({ generatedText });
    } catch (error: any) {
      console.error("AI generation error:", error);
      res.status(500).json({ error: error.message || "Failed to generate story settings" });
    }
  });

  app.post("/api/ai/generate-prologue", async (req, res) => {
    try {
      const { title, description, genre, storySettings, provider: requestedProvider } = req.body;
      
      // Try to find an available provider with API key
      const providers = ["gemini", "chatgpt", "claude", "grok"];
      let selectedProvider = requestedProvider;
      let apiKey = "";
      
      if (requestedProvider && requestedProvider !== "auto") {
        const apiKeySetting = await storage.getSetting(`apiKey_${requestedProvider}`);
        if (!apiKeySetting || !apiKeySetting.value) {
          return res.status(400).json({ error: `API key for ${requestedProvider} not configured.` });
        }
        apiKey = apiKeySetting.value;
        selectedProvider = requestedProvider;
      } else {
        for (const p of providers) {
          const apiKeySetting = await storage.getSetting(`apiKey_${p}`);
          if (apiKeySetting && apiKeySetting.value) {
            apiKey = apiKeySetting.value;
            selectedProvider = p;
            break;
          }
        }
        
        if (!apiKey) {
          return res.status(400).json({ error: "No AI API key configured." });
        }
      }
      
      // Get custom prompt template
      const customPromptSetting = await storage.getSetting("prologueGeneratePrompt");
      
      let prompt = customPromptSetting?.value || `ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¤ë¡œê·¸ì™€ ì‹œì‘ ìƒí™©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì œëª©: {title}
í•œ ì¤„ ì†Œê°œ: {description}
ì¥ë¥´: {genre}
ìŠ¤í† ë¦¬ ì„¤ì •: {storySettings}

ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
{
  "prologue": "ìŠ¤í† ë¦¬ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ” ëª°ì…ê° ìˆê³  ìƒìƒí•œ í”„ë¡¤ë¡œê·¸ë¥¼ í•œêµ­ì–´ë¡œ ì‘ì„±. 200ì ì´ìƒ.",
  "startingSituation": "ì‚¬ìš©ìì˜ ì—­í• , ë“±ì¥ì¸ë¬¼ê³¼ì˜ ê´€ê³„, í˜„ì¬ ìƒí™©ì„ í•œêµ­ì–´ë¡œ ìƒì„¸íˆ ì„¤ëª…. 100ì ì´ìƒ."
}`;

      prompt = prompt
        .replace(/\{title\}/g, title || "")
        .replace(/\{description\}/g, description || "")
        .replace(/\{genre\}/g, genre || "")
        .replace(/\{storySettings\}/g, storySettings || "");

      // Get selected model
      const modelSetting = await storage.getSetting(`aiModel_${selectedProvider}`);
      const defaultModels: Record<string, string> = {
        gemini: "gemini-2.0-flash",
        chatgpt: "gpt-4o",
        claude: "claude-3-5-sonnet-20241022",
        grok: "grok-beta"
      };
      const selectedModel = modelSetting?.value || defaultModels[selectedProvider] || "";

      let generatedText = "";

      if (selectedProvider === "gemini") {
        // Gemini 3 Pro requires thinking mode, other models can disable it
        const isThinkingOnlyModel = selectedModel.includes("gemini-3-pro") || selectedModel.includes("gemini-2.5-pro");
        const generationConfig: Record<string, any> = { 
          temperature: 0.8, 
          maxOutputTokens: 8192
        };
        if (!isThinkingOnlyModel) {
          generationConfig.thinkingConfig = { thinkingBudget: 0 };
        }

        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/${selectedModel}:generateContent?key=${apiKey}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              contents: [{ parts: [{ text: prompt }] }],
              generationConfig
            })
          }
        );
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.candidates?.[0]?.content?.parts?.[0]?.text || "";
      } else if (selectedProvider === "chatgpt") {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [{ role: "user", content: prompt }],
            temperature: 0.8,
            max_tokens: 8192
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.choices?.[0]?.message?.content || "";
      } else if (selectedProvider === "claude") {
        const response = await fetch("https://api.anthropic.com/v1/messages", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01"
          },
          body: JSON.stringify({
            model: selectedModel,
            max_tokens: 8192,
            messages: [{ role: "user", content: prompt }]
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.content?.[0]?.text || "";
      } else if (selectedProvider === "grok") {
        const response = await fetch("https://api.x.ai/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [{ role: "user", content: prompt }],
            temperature: 0.8,
            max_tokens: 8192
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.choices?.[0]?.message?.content || "";
      }

      // Parse JSON from response
      try {
        // Extract JSON from the response (handle markdown code blocks)
        let jsonStr = generatedText;
        const jsonMatch = generatedText.match(/```(?:json)?\s*([\s\S]*?)```/);
        if (jsonMatch) {
          jsonStr = jsonMatch[1].trim();
        }
        
        const parsed = JSON.parse(jsonStr);
        res.json({ 
          prologue: parsed.prologue || "",
          startingSituation: parsed.startingSituation || ""
        });
      } catch (parseError) {
        // If JSON parsing fails, try to extract content another way
        res.json({ 
          prologue: generatedText,
          startingSituation: ""
        });
      }
    } catch (error: any) {
      console.error("AI prologue generation error:", error);
      res.status(500).json({ error: error.message || "Failed to generate prologue" });
    }
  });

  // ==================== AI CHAT API ====================

  app.post("/api/ai/chat", async (req, res) => {
    try {
      const { sessionId, userMessage } = req.body;
      
      // Get session data
      const session = await storage.getSession(sessionId);
      if (!session) {
        return res.status(404).json({ error: "Session not found" });
      }

      // Get story data
      const story = await storage.getStory(session.storyId);
      if (!story) {
        return res.status(404).json({ error: "Story not found" });
      }

      // Get conversation history
      const messages = await storage.getMessagesBySession(sessionId);
      
      // Format recent messages (ìµœëŒ€ 20ê°œ, ì˜¤ë˜ëœ ìˆœì„œë¶€í„°)
      const recentMessages = messages.slice(-20).map(msg => {
        const role = msg.role === 'user' ? 'ì‚¬ìš©ì' : 'AI';
        return `${role}: ${msg.content}`;
      }).join('\n\n');
      
      // Use session-specific provider/model if set, otherwise use global settings
      const providers = ["gemini", "chatgpt", "claude", "grok"];
      let selectedProvider = session.sessionProvider || "";
      let selectedModel = session.sessionModel || "";
      let apiKey = "";
      
      if (selectedProvider) {
        // Use session-specific provider
        const apiKeySetting = await storage.getSetting(`apiKey_${selectedProvider}`);
        if (!apiKeySetting || !apiKeySetting.value) {
          return res.status(400).json({ error: `API key for ${selectedProvider} not configured.` });
        }
        apiKey = apiKeySetting.value;
      } else {
        // Auto-select: find first provider with API key
        for (const p of providers) {
          const apiKeySetting = await storage.getSetting(`apiKey_${p}`);
          if (apiKeySetting && apiKeySetting.value) {
            apiKey = apiKeySetting.value;
            selectedProvider = p;
            break;
          }
        }
        
        if (!apiKey) {
          return res.status(400).json({ error: "No AI API key configured." });
        }
      }
      
      // Get default model if not specified in session
      if (!selectedModel) {
        const modelSetting = await storage.getSetting(`aiModel_${selectedProvider}`);
        const defaultModels: Record<string, string> = {
          gemini: "gemini-2.0-flash",
          chatgpt: "gpt-4o",
          claude: "claude-3-5-sonnet-20241022",
          grok: "grok-beta"
        };
        selectedModel = modelSetting?.value || defaultModels[selectedProvider] || "";
      }
      
      // Build system prompt from AI persona settings (commonPrompt) with variable substitution
      const commonPromptSetting = await storage.getSetting("commonPrompt");
      let systemPrompt = commonPromptSetting?.value || `ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ íŒíƒ€ì§€ ì†Œì„¤ê°€ì…ë‹ˆë‹¤.
ìœ ì €ê°€ ì…ë ¥í•œ "ìœ ì € ë©”ì‹œì§€"ë¥¼ ë°”íƒ•ìœ¼ë¡œ í˜„ì¬ì„¸ê³„ê´€ê³¼ ì„¤ì •, í˜„ì¬ ì´ì•¼ê¸° íë¦„ì— ë§ì¶° ë‹¤ìŒ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê¸¸ì´ëŠ” ìµœì†Œ 1000ì ì´ìƒ ì¶œë ¥í•´ì•¼í•©ë‹ˆë‹¤.

## ìŠ¤í† ë¦¬ ì •ë³´
ì œëª©: {title}
ì¥ë¥´: {genre}
ì†Œê°œ: {description}

## ì„¸ê³„ê´€ ì„¤ì •
{storySettings}

## ì‹œì‘ ìƒí™©
{startingSituation}

## ëŒ€í™” í”„ë¡œí•„
{conversationProfile}

## ìœ ì € ë…¸íŠ¸
{userNote}

## ìš”ì•½ ë©”ëª¨ë¦¬
{summaryMemory}

## ìµœê·¼ ëŒ€í™” ê¸°ë¡
{recentMessages}

## ìœ ì € ë©”ì‹œì§€
{userMessage}

ìƒìƒí•˜ê³  ëª°ì…ê° ìˆëŠ” ì„œìˆ ê³¼ ëŒ€í™”ë¥¼ ì œê³µí•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.

-------
output:

{
  "nextStrory": "ì—¬ê¸°ì— ë‹¤ìŒì´ì•¼ê¸° ë‚´ìš©ì„ ì‘ì„±í•˜ì„¸ìš”."
}

nextStrory êµ¬ì„±:
- ë°°ê²½ì„¤ëª…: <Narration>ë‚´ìš©</Narration>
- ìºë¦­í„°ëŒ€í™”: <CharacterDialogue>ìºë¦­í„°ëª… | "ëŒ€ì‚¬"</CharacterDialogue>

ì¶”ê°€ ì„¤ëª…ì´ë‚˜ AI ì„œìˆ  ì—†ì´ ì •í™•íˆ JSON êµ¬ì¡°ë¡œ, ì˜¤ì§ 'nextStrory' í•­ëª©ë§Œ í¬í•¨í•´ ì£¼ì„¸ìš”.

ì¶œë ¥ì˜ˆì‹œ:
{
  "nextStrory": "<Narration>\\në¡ì‹œëŠ” ê°€ìŠ´ì„ ì«™ í´ê³  ë‹¹ë‹¹í•˜ê²Œ ì™¸ì³¤ë‹¤.\\n</Narration>\\n<CharacterDialogue>\\në¦¬ë‚˜ | \\"ì ê¹, ë¡ì‹œ. ê·¸ë ‡ê²Œ ë‹¨ìˆœí•œ ë¬¸ì œê°€ ì•„ë‹ˆì•¼.\\"\\n</CharacterDialogue>\\n<Narration>\\në¡ì‹œëŠ” ë¦¬ë‚˜ë¥¼ ë°”ë¼ë³´ë©° ê³ ê°œë¥¼ ê°¸ìš°ëš±í•œë‹¤.\\n</Narration>\\n<CharacterDialogue>\\në¡ì‹œ | \\"ë¬´ìŠ¨ë¬¸ì œ?\\"\\n</CharacterDialogue>"
}`;

      // Replace all variables with actual values
      systemPrompt = systemPrompt
        .replace(/\{title\}/g, story.title || "")
        .replace(/\{description\}/g, story.description || "")
        .replace(/\{genre\}/g, story.genre || "")
        .replace(/\{storySettings\}/g, story.storySettings || "")
        .replace(/\{startingSituation\}/g, story.startingSituation || "")
        .replace(/\{promptTemplate\}/g, story.promptTemplate || "")
        .replace(/\{exampleUserInput\}/g, story.exampleUserInput || "")
        .replace(/\{exampleAiResponse\}/g, story.exampleAiResponse || "")
        .replace(/\{conversationProfile\}/g, session.conversationProfile || "")
        .replace(/\{userNote\}/g, session.userNote || "")
        .replace(/\{summaryMemory\}/g, session.summaryMemory || "")
        .replace(/\{userMessage\}/g, userMessage || "")
        .replace(/\{recentMessages\}/g, recentMessages || "");

      // Log the prompt for debugging
      console.log("\n========== AI ì±„íŒ… í”„ë¡¬í”„íŠ¸ ==========");
      console.log("Provider:", selectedProvider);
      console.log("Model:", selectedModel);
      console.log("\n----- ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ -----");
      console.log(systemPrompt);
      console.log("\n----- ì‚¬ìš©ì ë©”ì‹œì§€ -----");
      console.log(userMessage);
      console.log("=====================================\n");

      let generatedText = "";

      // Build conversation history for API
      const conversationHistory = messages.map(msg => ({
        role: msg.role === "assistant" ? "assistant" : "user",
        content: msg.content
      }));
      conversationHistory.push({ role: "user", content: userMessage });

      if (selectedProvider === "gemini") {
        const geminiContents = [
          { role: "user", parts: [{ text: systemPrompt }] },
          { role: "model", parts: [{ text: "ì•Œê² ìŠµë‹ˆë‹¤. í•´ë‹¹ ìŠ¤í† ë¦¬ ì„¸ê³„ê´€ì— ë§ê²Œ ì‘ë‹µí•˜ê² ìŠµë‹ˆë‹¤." }] },
          ...conversationHistory.map(msg => ({
            role: msg.role === "assistant" ? "model" : "user",
            parts: [{ text: msg.content }]
          }))
        ];

        // Gemini 3 Pro requires thinking mode, other models can disable it
        const isThinkingOnlyModel = selectedModel.includes("gemini-3-pro") || selectedModel.includes("gemini-2.5-pro");
        const generationConfig: Record<string, any> = { 
          temperature: 0.9, 
          maxOutputTokens: 65536
        };
        
        // Only add thinkingConfig to disable thinking for non-thinking-only models
        if (!isThinkingOnlyModel) {
          generationConfig.thinkingConfig = { thinkingBudget: 0 };
        }

        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/${selectedModel}:generateContent?key=${apiKey}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              contents: geminiContents,
              generationConfig
            })
          }
        );
        const data = await response.json();
        console.log("Gemini API Response:", JSON.stringify(data, null, 2));
        
        if (data.error) {
          console.error("Gemini API Error:", data.error);
          return res.status(400).json({ error: data.error.message });
        }
        if (!response.ok) {
          console.error("Gemini API HTTP Error:", response.status, data);
          return res.status(400).json({ error: `Gemini API error: ${response.status}` });
        }
        
        // Check if content is empty
        const candidate = data.candidates?.[0];
        if (!candidate || !candidate.content || !candidate.content.parts || candidate.content.parts.length === 0) {
          const finishReason = candidate?.finishReason || "UNKNOWN";
          console.error("Gemini API returned empty content. Finish reason:", finishReason);
          
          if (finishReason === "MAX_TOKENS") {
            return res.status(400).json({ 
              error: "AI ì‘ë‹µì´ ë„ˆë¬´ ê¸¸ì–´ì„œ ìƒì„±ë˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë³€ê²½í•˜ê±°ë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë‹¨ìˆœí™”í•´ì£¼ì„¸ìš”." 
            });
          }
          
          return res.status(400).json({ 
            error: `AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤ (ì´ìœ : ${finishReason}). ë‹¤ë¥¸ ëª¨ë¸ì„ ì‹œë„í•´ë³´ì„¸ìš”.` 
          });
        }
        
        generatedText = candidate.content.parts[0]?.text || "";
      } else if (selectedProvider === "chatgpt") {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [
              { role: "system", content: systemPrompt },
              ...conversationHistory
            ],
            temperature: 0.9,
            max_tokens: 8192
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.choices?.[0]?.message?.content || "";
      } else if (selectedProvider === "claude") {
        const response = await fetch("https://api.anthropic.com/v1/messages", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01"
          },
          body: JSON.stringify({
            model: selectedModel,
            max_tokens: 8192,
            system: systemPrompt,
            messages: conversationHistory
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.content?.[0]?.text || "";
      } else if (selectedProvider === "grok") {
        const response = await fetch("https://api.x.ai/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [
              { role: "system", content: systemPrompt },
              ...conversationHistory
            ],
            temperature: 0.9,
            max_tokens: 8192
          })
        });
        const data = await response.json();
        if (data.error) {
          return res.status(400).json({ error: data.error.message });
        }
        generatedText = data.choices?.[0]?.message?.content || "";
      }

      // Try to parse JSON response if it looks like JSON
      let finalResponse = generatedText;
      try {
        // Remove markdown code blocks if present
        let cleanedText = generatedText.replace(/```json\n?/g, '').replace(/```\n?/g, '').trim();
        
        // Try to parse as JSON
        if (cleanedText.startsWith('{') && cleanedText.includes('nextStrory')) {
          // Extract only the nextStrory field value using regex
          // This is more robust than trying to fix the entire JSON
          const nextStroryMatch = cleanedText.match(/"nextStrory"\s*:\s*"((?:[^"\\]|\\.)*)"/);
          
          if (nextStroryMatch && nextStroryMatch[1]) {
            // Extract the nextStrory value and unescape it
            finalResponse = nextStroryMatch[1]
              .replace(/\\n/g, '\n')  // Convert \n to actual newlines
              .replace(/\\"/g, '"')   // Convert \" to "
              .replace(/\\'/g, "'")   // Convert \' to '
              .replace(/&lt;/g, '<')  // Convert &lt; to <
              .replace(/&gt;/g, '>'); // Convert &gt; to >
            console.log("Extracted nextStrory field using regex");
          } else {
            // Fallback: Try to parse the entire JSON
            const parsed = JSON.parse(cleanedText);
            if (parsed.nextStrory) {
              finalResponse = parsed.nextStrory
                .replace(/\\n/g, '\n')
                .replace(/\\"/g, '"')
                .replace(/\\'/g, "'")
                .replace(/&lt;/g, '<')
                .replace(/&gt;/g, '>');
              console.log("Parsed JSON response successfully");
            }
          }
        }
      } catch (parseError) {
        // If parsing fails, use the original text
        console.log("Response is not JSON, using raw text:", parseError);
      }

      res.json({ response: finalResponse, provider: selectedProvider, model: selectedModel });
    } catch (error: any) {
      console.error("AI chat error:", error);
      res.status(500).json({ error: error.message || "Failed to generate AI response" });
    }
  });

  // ==================== AI CHAT STREAMING API ====================

  app.post("/api/ai/chat/stream", async (req, res) => {
    try {
      const { sessionId, userMessage, storyId } = req.body;

      if (!sessionId || !userMessage || !storyId) {
        return res.status(400).json({ error: "sessionId, userMessage, and storyId are required" });
      }

      const story = await storage.getStory(storyId);
      if (!story) {
        return res.status(404).json({ error: "Story not found" });
      }

      const session = await storage.getSession(sessionId);
      if (!session) {
        return res.status(404).json({ error: "Session not found" });
      }

      // Get provider and model from session or settings
      let selectedProvider = session.sessionProvider || "gemini";
      let selectedModel = session.sessionModel || "";

      // Get API key
      const apiKeySetting = await storage.getSetting(`apiKey_${selectedProvider}`);
      if (!apiKeySetting || !apiKeySetting.value) {
        return res.status(400).json({ error: `API key for ${selectedProvider} not configured` });
      }
      const apiKey = apiKeySetting.value;

      // Get default model if not set
      if (!selectedModel) {
        const modelSetting = await storage.getSetting(`aiModel_${selectedProvider}`);
        const defaultModels: Record<string, string> = {
          gemini: "gemini-2.0-flash",
          chatgpt: "gpt-4o",
          claude: "claude-3-5-sonnet-20241022",
          grok: "grok-beta"
        };
        selectedModel = modelSetting?.value || defaultModels[selectedProvider] || "";
      }

      // Get messages for context
      const messages = await storage.getMessagesBySession(sessionId);

      // Get common prompt template
      const commonPromptSetting = await storage.getSetting("commonPrompt");
      let systemPrompt = commonPromptSetting?.value || `ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤. ë‹¤ìŒ ìŠ¤í† ë¦¬ë¥¼ ì´ì–´ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.`;

      // Build recent messages string (ìµœëŒ€ 20ê°œ)
      const recentMessages = messages.slice(-20).map(m => 
        `${m.role === 'user' ? 'ìœ ì €' : 'AI'}: ${m.content}`
      ).join('\n\n');

      // Replace all variables
      systemPrompt = systemPrompt
        .replace(/\{title\}/g, story.title || "")
        .replace(/\{description\}/g, story.description || "")
        .replace(/\{genre\}/g, story.genre || "")
        .replace(/\{storySettings\}/g, story.storySettings || "")
        .replace(/\{startingSituation\}/g, story.startingSituation || "")
        .replace(/\{promptTemplate\}/g, story.promptTemplate || "")
        .replace(/\{exampleUserInput\}/g, story.exampleUserInput || "")
        .replace(/\{exampleAiResponse\}/g, story.exampleAiResponse || "")
        .replace(/\{conversationProfile\}/g, session.conversationProfile || "")
        .replace(/\{userNote\}/g, session.userNote || "")
        .replace(/\{summaryMemory\}/g, session.summaryMemory || "")
        .replace(/\{userMessage\}/g, userMessage || "")
        .replace(/\{recentMessages\}/g, recentMessages || "");

      // Build conversation history (ìµœëŒ€ 20ê°œë¡œ ì œí•œí•˜ì—¬ í† í° ì ˆì•½)
      const recentMessagesForApi = messages.slice(-20);
      const conversationHistory = recentMessagesForApi.map(msg => ({
        role: msg.role === "assistant" ? "assistant" : "user",
        content: msg.content
      }));
      conversationHistory.push({ role: "user", content: userMessage });

      // Set up SSE headers
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');
      res.setHeader('X-Accel-Buffering', 'no');

      console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
      console.log("â•‘ ğŸ“¤ AI ìš”ì²­ ì‹œì‘");
      console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
      console.log("â•‘ Provider:", selectedProvider);
      console.log("â•‘ Model:", selectedModel);
      console.log("â•‘ Session ID:", sessionId);
      console.log("â•‘ ëŒ€í™” ê¸°ë¡ ê°œìˆ˜:", conversationHistory.length, "ê°œ (ìµœê·¼ 20ê°œ)");
      console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
      console.log("â•‘ ğŸ’¬ ì‚¬ìš©ì ë©”ì‹œì§€:");
      console.log("â•‘", userMessage.substring(0, 100) + (userMessage.length > 100 ? "..." : ""));
      console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
      console.log("â•‘ ğŸ“‹ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì²« 200ì):");
      console.log("â•‘", systemPrompt.substring(0, 200).replace(/\n/g, "\nâ•‘ ") + "...");
      console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      if (selectedProvider === "gemini") {
        const geminiContents = [
          { role: "user", parts: [{ text: systemPrompt }] },
          { role: "model", parts: [{ text: "ì•Œê² ìŠµë‹ˆë‹¤. í•´ë‹¹ ìŠ¤í† ë¦¬ ì„¸ê³„ê´€ì— ë§ê²Œ ì‘ë‹µí•˜ê² ìŠµë‹ˆë‹¤." }] },
          ...conversationHistory.map(msg => ({
            role: msg.role === "assistant" ? "model" : "user",
            parts: [{ text: msg.content }]
          }))
        ];

        const isThinkingOnlyModel = selectedModel.includes("gemini-3-pro") || selectedModel.includes("gemini-2.5-pro");
        const generationConfig: Record<string, any> = { 
          temperature: 0.9, 
          maxOutputTokens: 65536
        };
        
        if (!isThinkingOnlyModel) {
          generationConfig.thinkingConfig = { thinkingBudget: 0 };
        }

        // Use streaming endpoint
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/${selectedModel}:streamGenerateContent?alt=sse&key=${apiKey}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              contents: geminiContents,
              generationConfig
            })
          }
        );

        if (!response.ok) {
          const errorData = await response.json();
          console.error("Gemini Stream Error:", errorData);
          res.write(`data: ${JSON.stringify({ error: errorData.error?.message || "Streaming failed" })}\n\n`);
          res.end();
          return;
        }

        const reader = response.body?.getReader();
        if (!reader) {
          res.write(`data: ${JSON.stringify({ error: "Failed to get stream reader" })}\n\n`);
          res.end();
          return;
        }

        const decoder = new TextDecoder();
        let fullText = "";
        let buffer = "";

        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || "";

            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6).trim();
                if (jsonStr && jsonStr !== '[DONE]') {
                  try {
                    const data = JSON.parse(jsonStr);
                    const text = data.candidates?.[0]?.content?.parts?.[0]?.text || "";
                    if (text) {
                      fullText += text;
                      res.write(`data: ${JSON.stringify({ text, done: false })}\n\n`);
                    }
                  } catch (parseErr) {
                    // Skip malformed JSON
                  }
                }
              }
            }
          }
        } catch (streamErr) {
          console.error("Stream reading error:", streamErr);
        }

        // Send final message with full text
        res.write(`data: ${JSON.stringify({ text: "", done: true, fullText })}\n\n`);
        res.end();

        console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ âœ… AI ì‘ë‹µ ì™„ë£Œ (Gemini)");
        console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ ì‘ë‹µ ê¸¸ì´:", fullText.length, "ì");
        console.log("â•‘ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²« 200ì):");
        console.log("â•‘", fullText.substring(0, 200).replace(/\n/g, "\nâ•‘ ") + (fullText.length > 200 ? "..." : ""));
        console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      } else if (selectedProvider === "chatgpt") {
        const response = await fetch("https://api.openai.com/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [
              { role: "system", content: systemPrompt },
              ...conversationHistory
            ],
            temperature: 0.9,
            max_tokens: 8192,
            stream: true
          })
        });

        if (!response.ok) {
          const errorData = await response.json();
          res.write(`data: ${JSON.stringify({ error: errorData.error?.message || "Streaming failed" })}\n\n`);
          res.end();
          return;
        }

        const reader = response.body?.getReader();
        if (!reader) {
          res.write(`data: ${JSON.stringify({ error: "Failed to get stream reader" })}\n\n`);
          res.end();
          return;
        }

        const decoder = new TextDecoder();
        let fullText = "";
        let buffer = "";

        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || "";

            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6).trim();
                if (jsonStr && jsonStr !== '[DONE]') {
                  try {
                    const data = JSON.parse(jsonStr);
                    const text = data.choices?.[0]?.delta?.content || "";
                    if (text) {
                      fullText += text;
                      res.write(`data: ${JSON.stringify({ text, done: false })}\n\n`);
                    }
                  } catch (parseErr) {
                    // Skip malformed JSON
                  }
                }
              }
            }
          }
        } catch (streamErr) {
          console.error("Stream reading error:", streamErr);
        }

        res.write(`data: ${JSON.stringify({ text: "", done: true, fullText })}\n\n`);
        res.end();

        console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ âœ… AI ì‘ë‹µ ì™„ë£Œ (ChatGPT)");
        console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ ì‘ë‹µ ê¸¸ì´:", fullText.length, "ì");
        console.log("â•‘ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²« 200ì):");
        console.log("â•‘", fullText.substring(0, 200).replace(/\n/g, "\nâ•‘ ") + (fullText.length > 200 ? "..." : ""));
        console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      } else if (selectedProvider === "claude") {
        const response = await fetch("https://api.anthropic.com/v1/messages", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "x-api-key": apiKey,
            "anthropic-version": "2023-06-01"
          },
          body: JSON.stringify({
            model: selectedModel,
            max_tokens: 8192,
            system: systemPrompt,
            messages: conversationHistory,
            stream: true
          })
        });

        if (!response.ok) {
          const errorData = await response.json();
          res.write(`data: ${JSON.stringify({ error: errorData.error?.message || "Streaming failed" })}\n\n`);
          res.end();
          return;
        }

        const reader = response.body?.getReader();
        if (!reader) {
          res.write(`data: ${JSON.stringify({ error: "Failed to get stream reader" })}\n\n`);
          res.end();
          return;
        }

        const decoder = new TextDecoder();
        let fullText = "";
        let buffer = "";

        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || "";

            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6).trim();
                if (jsonStr) {
                  try {
                    const data = JSON.parse(jsonStr);
                    if (data.type === 'content_block_delta' && data.delta?.text) {
                      const text = data.delta.text;
                      fullText += text;
                      res.write(`data: ${JSON.stringify({ text, done: false })}\n\n`);
                    }
                  } catch (parseErr) {
                    // Skip malformed JSON
                  }
                }
              }
            }
          }
        } catch (streamErr) {
          console.error("Stream reading error:", streamErr);
        }

        res.write(`data: ${JSON.stringify({ text: "", done: true, fullText })}\n\n`);
        res.end();

        console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ âœ… AI ì‘ë‹µ ì™„ë£Œ (Claude)");
        console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ ì‘ë‹µ ê¸¸ì´:", fullText.length, "ì");
        console.log("â•‘ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²« 200ì):");
        console.log("â•‘", fullText.substring(0, 200).replace(/\n/g, "\nâ•‘ ") + (fullText.length > 200 ? "..." : ""));
        console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      } else if (selectedProvider === "grok") {
        const response = await fetch("https://api.x.ai/v1/chat/completions", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Authorization": `Bearer ${apiKey}`
          },
          body: JSON.stringify({
            model: selectedModel,
            messages: [
              { role: "system", content: systemPrompt },
              ...conversationHistory
            ],
            temperature: 0.9,
            max_tokens: 8192,
            stream: true
          })
        });

        if (!response.ok) {
          const errorData = await response.json();
          res.write(`data: ${JSON.stringify({ error: errorData.error?.message || "Streaming failed" })}\n\n`);
          res.end();
          return;
        }

        const reader = response.body?.getReader();
        if (!reader) {
          res.write(`data: ${JSON.stringify({ error: "Failed to get stream reader" })}\n\n`);
          res.end();
          return;
        }

        const decoder = new TextDecoder();
        let fullText = "";
        let buffer = "";

        try {
          while (true) {
            const { done, value } = await reader.read();
            if (done) break;

            buffer += decoder.decode(value, { stream: true });
            const lines = buffer.split('\n');
            buffer = lines.pop() || "";

            for (const line of lines) {
              if (line.startsWith('data: ')) {
                const jsonStr = line.slice(6).trim();
                if (jsonStr && jsonStr !== '[DONE]') {
                  try {
                    const data = JSON.parse(jsonStr);
                    const text = data.choices?.[0]?.delta?.content || "";
                    if (text) {
                      fullText += text;
                      res.write(`data: ${JSON.stringify({ text, done: false })}\n\n`);
                    }
                  } catch (parseErr) {
                    // Skip malformed JSON
                  }
                }
              }
            }
          }
        } catch (streamErr) {
          console.error("Stream reading error:", streamErr);
        }

        res.write(`data: ${JSON.stringify({ text: "", done: true, fullText })}\n\n`);
        res.end();

        console.log("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ âœ… AI ì‘ë‹µ ì™„ë£Œ (Grok)");
        console.log("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        console.log("â•‘ ì‘ë‹µ ê¸¸ì´:", fullText.length, "ì");
        console.log("â•‘ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²« 200ì):");
        console.log("â•‘", fullText.substring(0, 200).replace(/\n/g, "\nâ•‘ ") + (fullText.length > 200 ? "..." : ""));
        console.log("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

      } else {
        // Fallback for unknown providers
        res.write(`data: ${JSON.stringify({ error: "ì§€ì›í•˜ì§€ ì•ŠëŠ” AI í”„ë¡œë°”ì´ë”ì…ë‹ˆë‹¤." })}\n\n`);
        res.end();
      }

    } catch (error: any) {
      console.error("AI streaming error:", error);
      res.write(`data: ${JSON.stringify({ error: error.message || "Streaming failed" })}\n\n`);
      res.end();
    }
  });

  // ==================== MESSAGES API ====================

  app.get("/api/sessions/:sessionId/messages", async (req, res) => {
    try {
      const sessionId = parseInt(req.params.sessionId);
      if (isNaN(sessionId)) {
        return res.status(400).json({ error: "Invalid session ID" });
      }

      const msgs = await storage.getMessagesBySession(sessionId);
      res.json(msgs);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch messages" });
    }
  });

  app.post("/api/sessions/:sessionId/messages", async (req, res) => {
    try {
      const sessionId = parseInt(req.params.sessionId);
      if (isNaN(sessionId)) {
        return res.status(400).json({ error: "Invalid session ID" });
      }

      const messageData = { ...req.body, sessionId };
      const parsed = insertMessageSchema.safeParse(messageData);
      if (!parsed.success) {
        return res.status(400).json({ error: "Invalid message data", details: parsed.error });
      }

      const message = await storage.createMessage(parsed.data);
      res.status(201).json(message);
    } catch (error) {
      res.status(500).json({ error: "Failed to create message" });
    }
  });

  app.delete("/api/sessions/:sessionId/messages", async (req, res) => {
    try {
      const sessionId = parseInt(req.params.sessionId);
      if (isNaN(sessionId)) {
        return res.status(400).json({ error: "Invalid session ID" });
      }

      await storage.deleteMessagesBySession(sessionId);
      res.json({ success: true });
    } catch (error) {
      res.status(500).json({ error: "Failed to delete messages" });
    }
  });

  return httpServer;
}
